import onnx
import numpy as np
import onnxruntime as ort

def inspect_model(path: str):
    model = onnx.load(path)
    graph = model.graph

    print("\n=== ðŸ” æ¨¡åž‹ I/O ä¿¡æ¯ ===")
    print("Inputs:")
    for inp in graph.input:
        t = inp.type.tensor_type
        shape = [d.dim_value if d.dim_value > 0 else "dynamic" for d in t.shape.dim]
        print(f" - name={inp.name}, shape={shape}, dtype={t.elem_type}")

    print("\nOutputs:")
    for out in graph.output:
        t = out.type.tensor_type
        shape = [d.dim_value if d.dim_value > 0 else "dynamic" for d in t.shape.dim]
        print(f" - name={out.name}, shape={shape}, dtype={t.elem_type}")

    print("\n=== ðŸ”Ž æ£€æŸ¥æ˜¯å¦åŒ…å«æ ‡å‡†åŒ–è¿ç®— ===")
    op_types = set([n.op_type for n in graph.node])
    print("Operators:", op_types)

    if {"Sub", "Div"} & op_types:
        print("âœ… æ£€æµ‹åˆ° Sub/Div è¿ç®—ï¼Œè¯´æ˜Ž Normalize å¾ˆå¯èƒ½å·²ç»è¢«å†™å…¥ ONNX å›¾ä¸­")
    else:
        print("âŒ æœªå‘çŽ° Sub/Divï¼ŒNormalize å¾ˆå¯èƒ½åœ¨å¤–éƒ¨ï¼ˆC++å¿…é¡»æ‰‹åŠ¨å®žçŽ°ï¼‰")

    # ç”¨éšæœºè¾“å…¥è·‘ä¸€éæŽ¨ç†å°è¯•æŽ¨æµ‹è¾“å‡ºèŒƒå›´
    print("\n=== â–¶ï¸ æµ‹è¯•ä¸€æ¬¡æŽ¨ç†è¾“å‡ºèŒƒå›´ ===")
    sess = ort.InferenceSession(path)
    input_node = sess.get_inputs()[0]
    shape = input_node.shape

    # æž„é€ éšæœºå¼ é‡ï¼ˆå…¨éƒ¨å¡«å…… 0.5ï¼Œç­‰ä»·å›¾åƒä¸­å¿ƒåƒç´ ï¼‰
    fake = np.ones([d if isinstance(d, int) and d > 0 else 1 for d in shape], dtype=np.float32) * 0.5
    out = sess.run(None, {input_node.name: fake})[0]
    print("Output sample:", out)
    print("Output shape:", out.shape)
    print("Output range:", float(np.min(out)), "to", float(np.max(out)))

if __name__ == "__main__":
    inspect_model("../models/cnn_haze.onnx")

